# Diffulex Benchmark Configuration Example
# This is a YAML configuration file for running benchmarks with Diffulex

# Model configuration
model_path: "/path/to/your/model"
tokenizer_path: null  # Optional, defaults to model_path
model_name: "dream"  # Options: dream, sdar, fast_dllm_v2
decoding_strategy: "d2f"  # Options: d2f, block_diffusion, fast_dllm
mask_token_id: 151666

# Inference configuration
tensor_parallel_size: 1
data_parallel_size: 1
gpu_memory_utilization: 0.9
max_model_len: 2048
max_num_batched_tokens: 4096
max_num_seqs: 128

# Sampling configuration
temperature: 0.0
max_tokens: 256
ignore_eos: false

# Dataset configuration
dataset_name: "gsm8k"  # Options: gsm8k, humaneval, etc.
dataset_split: "test"
dataset_limit: 100  # Optional, limit number of samples

# LoRA configuration
use_lora: false
lora_path: ""

# Engine configuration
enforce_eager: false
kv_cache_layout: "unified"  # Options: unified, distinct

# D2F-specific configuration
accept_threshold: 0.9
complete_threshold: 0.95
add_new_block_threshold: 0.1
diffusion_block_size: 32

# Output configuration
output_dir: "benchmark_results"
save_results: true
use_tqdm: true

